---
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: &app localai
  namespace: default
spec:
  interval: 30m
  chart:
    spec:
      # renovate: registryUrl=https://go-skynet.github.io/helm-charts/
      chart: localai
      version: 2.1.2
      sourceRef:
        kind: HelmRepository
        name: go-skynet
        namespace: flux-system
  maxHistory: 2
  install:
    createNamespace: true
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3
  uninstall:
    keepHistory: false
  values:
    replicaCount: 1
    deployment:
      image: quay.io/go-skynet/local-ai:latest
      env:
        threads: 14
        context_size: 512
        rebuild: false
        debug: true
      modelsPath: "/models"
    resources:
      requests:
        cpu: 250m
        memory: 6G
      limits:
        memory: 6G

    promptTemplates:
      ggml-gpt4all-j.tmpl: |
        The prompt below is a question to answer, a task to complete, or a conversation to respond to; decide which and write an appropriate response.
        ### Prompt:
        {{.Input}}
        ### Response:
      llama-2-7b-chat.ggmlv3.q4_0.tmpl: |
        The prompt below is a question to answer, a task to complete, or a conversation to respond to; decide which and write an appropriate response.
        ### Prompt:
        {{.Input}}
        ### Response:
    models:
      forceDownload: false
      list:
        - url: "https://gpt4all.io/models/ggml-gpt4all-j.bin"
        - url: "https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML/resolve/main/llama-2-7b-chat.ggmlv3.q4_0.bin"
        # basicAuth: base64EncodedCredentials
      persistence:
        pvc:
          enabled: true
          size: 20Gi
          accessModes:
            - ReadWriteOnce
          annotations: {}

    service:
      type: LoadBalancer
      ports:
        http:
          port: 8080

    ingress:
      enabled: true
      ingressClassName: nginx
      annotations:
        nginx.ingress.kubernetes.io/whitelist-source-range: |
          10.0.0.0/8,172.16.0.0/12,192.168.0.0/16
        cert-manager.io/cluster-issuer: letsencrypt-production
        external-dns.alpha.kubernetes.io/target: "ingress.${SECRET_DOMAIN}"
        external-dns.home.arpa/enabled: "true"
      hosts:
        - host: &host localai.${SECRET_DOMAIN}
          paths:
            - path: /
              pathType: Prefix
      tls:
        - hosts:
            - *host
          secretName: localai-tls
